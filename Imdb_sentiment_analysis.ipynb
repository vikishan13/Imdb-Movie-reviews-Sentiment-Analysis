{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPefvPKub6APESN+5w7xu/I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vikishan13/Imdb-Movie-reviews-Sentiment-Analysis/blob/main/Imdb_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w81LKfJx4hqL",
        "outputId": "88c9ea2d-0e6d-4c22-ab75-752c281b4f94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "oPuEQNux4rKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb, info = tfds.load(\"imdb_reviews\", with_info = True, as_supervised=True)"
      ],
      "metadata": {
        "id": "tDEH0nDb4xVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = imdb['train'], imdb['test']"
      ],
      "metadata": {
        "id": "YaDSXTtp4-hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "Xf_lrjRz6UDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain = []\n",
        "ytrain = []\n",
        "xtest = []\n",
        "ytest = []\n",
        "for x, y in train_data:\n",
        "  xtrain.append(x.numpy().decode('utf-8')) # Extracting text from tensorflow datatype\n",
        "  ytrain.append(y.numpy())\n",
        "\n",
        "for x,y in test_data:\n",
        "  xtest.append(x.numpy().decode('utf-8'))\n",
        "  ytest.append(y.numpy())"
      ],
      "metadata": {
        "id": "M9S8U45X5VJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "mKJbnaap6ReC",
        "outputId": "739022f5-b427-4b0c-aac0-27749e907ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JFDnOX66Kzs",
        "outputId": "81a5244b-a27d-4191-a7fd-219226f5c761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 1, 1, 1, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The values needs to be in numpy array before passing into Neural Networks\n",
        "ytrain = np.array(ytrain)\n",
        "ytest = np.array(ytest)"
      ],
      "metadata": {
        "id": "dkvDex9277O_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYKQQGda8Q2T",
        "outputId": "407b5b2f-a58e-4b0d-c00c-c04efbad0545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 1, 1, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining Hyperparameters for the model\n",
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 120"
      ],
      "metadata": {
        "id": "Un1DOD9C8eI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "mnn5EXBq8idT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token = \"<OOV>\")"
      ],
      "metadata": {
        "id": "SS5Uh8OI9N8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(xtrain)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(xtrain)\n",
        "padded = pad_sequences(sequences, maxlen = max_length, truncating = 'post')"
      ],
      "metadata": {
        "id": "Ypy885VI9_XJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sequences = tokenizer.texts_to_sequences(xtest)\n",
        "test_padded = pad_sequences(test_sequences, maxlen = max_length, truncating = 'post')"
      ],
      "metadata": {
        "id": "BspQFYMz-VH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(6, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "o2AmXNuOAZY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "6OSlcnqxDHvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(padded, ytrain, epochs = 10, validation_data=(test_padded, ytest))\n",
        "# Reminder: slight overfitting is noticed in the model, can use Early Stopping and Patience to control overfitting / Hyperparameter tunings need to be done"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LV9RkF1DOd1",
        "outputId": "7db7c2a9-6bbc-4d5b-96f0-8610dde2f399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 7s 7ms/step - loss: 0.5025 - accuracy: 0.7334 - val_loss: 0.3870 - val_accuracy: 0.8238\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.2486 - accuracy: 0.9040 - val_loss: 0.3998 - val_accuracy: 0.8254\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.1107 - accuracy: 0.9695 - val_loss: 0.4922 - val_accuracy: 0.8124\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0312 - accuracy: 0.9957 - val_loss: 0.5899 - val_accuracy: 0.8105\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.0090 - accuracy: 0.9992 - val_loss: 0.6630 - val_accuracy: 0.8113\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.7362 - val_accuracy: 0.8069\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7927 - val_accuracy: 0.8083\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 5.4898e-04 - accuracy: 1.0000 - val_loss: 0.8429 - val_accuracy: 0.8084\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 3.2151e-04 - accuracy: 1.0000 - val_loss: 0.8898 - val_accuracy: 0.8092\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.8424e-04 - accuracy: 1.0000 - val_loss: 0.9325 - val_accuracy: 0.8083\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7877ec733370>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = ['i watched this movie which was absolutely superb and lovely to watch and i loved the movie very much']\n",
        "text_sequences = tokenizer.texts_to_sequences(text)\n",
        "pred = pad_sequences(text_sequences, maxlen = max_length, truncating = 'post')"
      ],
      "metadata": {
        "id": "ZIuVNyo6D-_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value = model.predict(pred)\n",
        "print(value)\n",
        "print(\"positive review\") if value > 0.5 else print(\"negative negative\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNhDgt5gEqHp",
        "outputId": "9243bee4-f605-4f92-f022-80621162304d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 97ms/step\n",
            "[[0.9958978]]\n",
            "positive review\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = ['i watched this movie which was terrific and waste of money to watch and i hated this movie and those directors were taken this movie just for timesake']\n",
        "text_sequences = tokenizer.texts_to_sequences(text)\n",
        "pred = pad_sequences(text_sequences, maxlen = max_length, truncating = 'post')"
      ],
      "metadata": {
        "id": "bzz3DpivEr6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value = model.predict(pred)\n",
        "print(value)\n",
        "print(\"positive review\") if value > 0.5 else print(\"negative review\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dce2Jci8E6ow",
        "outputId": "78e42d7c-e20c-4f60-b2c0-291fc644fa5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "[[0.00279332]]\n",
            "negative review\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mdHCI7NyE9QY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}